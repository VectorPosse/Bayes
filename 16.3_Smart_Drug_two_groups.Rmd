---
title: "16.3: Smart Drug (two groups)"
output: html_notebook
---


## Introduction

This is the example from Section 16.3 of Kruschke on the (fictitious) effect of the "smart drug", this time comparing the "smart drug" group against the placebo group. Make sure the "TwoGroupIQ.csv" file is in your project directory.


## Preliminaries

Load necessary packages:

```{r, message = FALSE}
library(tidyverse)
library(rstan)
library(shinystan)
library(bayesplot)
```

Set Stan to save compiled code.

```{r}
rstan_options(auto_write = TRUE)
```

Set Stan to use parallel processing where possible.

```{r}
options(mc.cores = parallel::detectCores())
```


## Data

```{r}
IQ_data <- read_csv("TwoGroupIQ.csv")
IQ_data
```

Since we are now comparing both groups, we can use the whole data set (120 total observations: 63 experimental and 57 control):

```{r}
table(IQ_data$Group)
```

We will, however, need to give the groups numerical values to pass to Stan (rather than the strings "Smart Drug" and "Placebo"). The easiest way to do this is to `factor` the `Group` variable. This will change the underlying structure to 1s and 2s. Observe:

```{r}
x <- factor(IQ_data$Group,
            levels = c("Smart Drug", "Placebo"))
str(x)
```

Now "Smart Drug" is 1 and "Placebo" is 2. All we have to do is convert this factor variable into a vector of integers that Stan will accept.

```{r}
x <- as.integer(x)
```

And bundle everything together into a list:

```{r}
N <- NROW(IQ_data)
y <- IQ_data$Score
stan_data <- list(N = N, x = x, y = y)
```


## Stan code

Now we include the `x` variable that is either 1 or 2 to indicate group. We also let `mu` and `sigma` have two possible values.

The only change to the model is the likelihood:

```
y ~ student_t(nu, mu[x], sigma[x]);
```

The terms `mu[x]` and `sigma[x]` ensure that the `y` value is used only for the group to which that observation belongs (1 or 2).

One more interesting change is to the `generated quantities` block. We've only used this to generate random draws from our posterior for posterior predictive checks. But technically, we can calculate anything we want in this block. Since the difference of two means is the primary object of our inference, we compute a `diff` variable here as the difference in the two sampled values of `mu`.

```{stan, output.var = "IQ2", cache = TRUE}
data {
    int<lower = 0> N;
    int<lower = 1, upper = 2> x[N];
    real<lower = 0> y[N];
}
transformed data {
    real<lower = 0> Rate;
    real<lower = 0> M;
    real<lower = 0> S;
    real<lower = 0> L;
    real<lower = 0> H;
    
    Rate = 1.0/29.0;
    M = 100;
    S = 100;
    L = 0;
    H = 1000;
}
parameters {
    real<lower = 0> nu_minus_one;
    real<lower = 0> mu[2];
    real<lower = 0> sigma[2];
}
transformed parameters {
    real<lower = 0> nu;

    nu = nu_minus_one + 1;
}
model {
    nu_minus_one ~ exponential(Rate);
    mu ~ normal(M, S);
    sigma ~ uniform(L, H);
    y ~ student_t(nu, mu[x], sigma[x]);
}
generated quantities {
    real y_rep[N];
    real diff;
    
    for (n in 1:N) {
        y_rep[n] = student_t_rng(nu, mu[x[n]], sigma[x[n]]);
    }
    
    diff = mu[1] - mu[2];
}
```


## Sampling from the model

```{r}
set.seed(11111)
fit_IQ2 <- sampling(IQ2, data = stan_data, refresh = 0)
```


## Diagnosing the model

```{r}
plot(fit_IQ2, plotfun = "ac", pars = c("nu", "mu", "sigma"))
```

```{r}
plot(fit_IQ2, plotfun = "trace",
     pars = c("nu", "mu", "sigma"))
```


## Summarizing the model

```{r}
print(fit_IQ2, pars = c("nu", "mu", "sigma", "diff"))
```


## Visualizing the model

```{r}
pairs(fit_IQ2, pars = c("mu"))
```

```{r}
pairs(fit_IQ2, pars = c("sigma"))
```

```{r}
pairs(fit_IQ2, pars = c("mu[1]", "sigma[1]"))
```

```{r}
pairs(fit_IQ2, pars = c("mu[2]", "sigma[2]"))
```

```{r}
plot(fit_IQ2, plotfun = "dens", pars = c("nu", "mu", "sigma", "diff"))
```

```{r}
plot(fit_IQ2, pars = c("mu"))
```

```{r}
plot(fit_IQ2, pars = c("sigma"))
```

```{r}
plot(fit_IQ2, pars = c("diff"))
```


## Examining the prior

```{stan, output.var = "IQ2_prior", cache = TRUE}
data {
    int<lower = 0> N;
    int<lower = 1, upper = 2> x[N];
    real<lower = 0> y[N];
}
transformed data {
    real<lower = 0> Rate;
    real<lower = 0> M;
    real<lower = 0> S;
    real<lower = 0> L;
    real<lower = 0> H;
    
    Rate = 1.0/29.0;
    M = 100;
    S = 100;
    L = 0;
    H = 1000;
}
parameters {
    real<lower = 0> nu_minus_one;
    real<lower = 0> mu[2];
    real<lower = 0> sigma[2];
}
transformed parameters {
    real<lower = 0> nu;

    nu = nu_minus_one + 1;
}
model {
    nu_minus_one ~ exponential(Rate);
    mu ~ normal(M, S);
    sigma ~ uniform(L, H);
//    y ~ student_t(nu, mu[x], sigma[x]);
}
```

```{r}
set.seed(11111)
fit_IQ2_prior <- sampling(IQ2_prior, data = stan_data, refresh = 0)
```

```{r}
fit_IQ2_prior
```

```{r}
pairs(fit_IQ2_prior, pars = c("nu", "mu", "sigma"))
```

```{r}
plot(fit_IQ2_prior, pars = c("nu", "mu", "sigma"))
```


## Posterior predictive check

Extract predicted values:

```{r}
samples_IQ2 <- extract(fit_IQ2)
y_rep <- samples_IQ2$y_rep
```

There are interesting posterior predictive checks for grouped data.

```{r}
ppc_intervals_grouped(y, y_rep, group = x)
```


```{r}
ppc_stat_grouped(y, y_rep, group = x)
```

Or we can use the familiar ones as long as we're careful to subset. We'll make a vector of which y values belong to which group:

```{r}
drug <- which(x == 1)
placebo <- which(x == 2)
```

```{r}
ppc_hist(y[drug], y_rep[1:5, drug])
```

```{r}
ppc_hist(y[placebo], y_rep[1:5, placebo])
```

```{r}
ppc_boxplot(y[drug], y_rep[1:5, drug])
```

```{r}
ppc_boxplot(y[placebo], y_rep[1:5, placebo])
```

```{r}
ppc_dens(y[drug], y_rep[1:5, drug])
```

```{r}
ppc_dens(y[placebo], y_rep[1:5, placebo])
```

```{r}
ppc_dens_overlay(y[drug], y_rep[1:30, drug])
```

```{r}
ppc_dens_overlay(y[placebo], y_rep[1:30, placebo])
```

```{r}
ppc_stat_2d(y[drug], y_rep[ , drug])
```

```{r}
ppc_stat_2d(y[placebo], y_rep[ , placebo])
```

Just for giggles, let's also check that we can recover our `diff` parameter from the extracted samples:

```{r}
test_diff <- samples_IQ2$mu[ ,1] - samples_IQ2$mu[ ,2]
head(test_diff)
```

```{r}
head(samples_IQ2$diff)
```

So we could also have calculated the difference of means manually, but the benefit of doing it within the Stan code is that we can use all the Stan features to graph `diff` as a parameter rather than having to roll our own code to visualize `diff`.


## ShinyStan

Run the following code from the Console:

```
launch_shinystan(fit_IQ2)
```