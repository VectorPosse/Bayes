---
title: "First Stan examples"
output: html_notebook
---


## Introduction

Stan is a platform for running statistical computations, especially Bayesian data analysis. The mechanism by which it works (Hamiltonian Markov Chain Monte Carlo) is sophisticated. Here we'll describe how to set up a model and compute a posterior distribution.

The first time you run the code chunks in this file, it will take a while. Be patient. I've included options and code that will allow Stan to bypass a lot of the work R has to do the second time around (and every time thereafter, as long as you're in the same R session).


## Preliminaries

Load necessary packages:

```{r, message = FALSE, warning = FALSE}
library(rstan)
library(bayestestR)
```

Stan will take a fair amount of time the first time it's run on a model. The following bit of code tells Stan not to recompile code that has already been compiled once so that it won't take so long after the first time.

```{r}
rstan_options(auto_write = TRUE)
```

Finally, the following code will detect if there are multiple cores available for parallel processing, and if so, use those cores to speed up the sampling process.

```{r}
options(mc.cores = parallel::detectCores())
```


## Stan's structure

Stan code looks quite different from R code. (Stan is actually coded in C.) We'll see later, for example, that each line must terminate with a semicolon, and comments use two forward slashes.

There are three basic code blocks in a simple Stan program. The first is called `data` and it reads in the raw data. The second is `parameters` in which you tell Stan the parameters for which you're conducting statistical inference. The third is `model` where you describe the statistical model.

There are other, more advanced possibilities for code blocks, but those three suffice for a complete model.


## Storing the data

We re-create the analysis of 12 successes in 18 trials from the "Continuous Bayes" notes.

Stan is a little particular about the form of the data. It requires a `list` from R. Here's how we do that. First, just store the values we need.

```{r}
N1 <- 18  # Define the sample size
y1 <- c(rep(1, 12), rep(0, 6))  # 12 successes and 6 failures
```

The line defining `y` is just using an R trick to get 12 ones and 6 zeros. Observe:

```{r}
y1
```

Now we bundle `N` and `y` together into a list.

```{r}
stan_data <- list(N = N1, y = y1)
stan_data
```

This is the format required by Stan for accessing the data.


## Uniform prior

We'll start with assuming a uniform prior.

### The Stan code

R Markdown is awesome, so it gives us a way to create a Stan model within a code chunk. The resulting model is stored in the variable name specified by the `output.var` chunk option (in this case, `bin_unif`).

We also use the option `cache = TRUE` in the header of the code chunk. This chunk takes a while the first time it's run; however, once the result is cached, it won't run again even when you "Run All" code chunks. (You may also ignore any warnings that may appear below the chunk once it's finished running.)


```{stan, output.var = "bin_unif", cache = TRUE}
data {
    int<lower = 0> N;
    int<lower = 0, upper = 1> y[N];
}
parameters {
    real<lower = 0, upper = 1> theta;
}
model {
    theta ~ uniform(0, 1);  // prior
    y ~ bernoulli(theta);   // likelihood
}
```


Let's take a closer look at various pieces of the Stan code. Here is the `data` block:

```
data {
    int<lower = 0> N;
    int<lower = 0, upper = 1> y[N];
}
```

Notice that the two variables declared here are precisely the variables in the list `stan_data` (namely, `N`, and `y`). The `lower` and/or `upper` bounds in the definitions just serve as a check to make sure we are passing in data of the right form. (If invalid data is passed to Stan, the program will stop with an error.) The notation `y[N]` means that the variable `y` should be an array of `N` integers.

The `parameters` block is

```
parameters {
    real<lower = 0, upper = 1> theta;
}
```

This simply declares that we are interested in doing inference for a value called `theta`. The `lower` and `upper` bounds here serve a slightly different purpose. These tell Stan that it shouldn't consider values of `theta` unless they lie between 0 and 1.

The `model` block is

```
model {
    theta ~ uniform(0, 1);  // prior
    y ~ bernoulli(theta);   // likelihood
}
```

The first line is saying that we start with a uniform prior on `theta`. Technically, this line is not required: the parameter declaration `real<lower = 0, upper = 1> theta` defines a uniform $(0, 1)$ prior on `theta` by default. But we include it for completeness because in most situations, we won't use a uniform prior.

The second line is the likelihood function. An event that consists of a success/failure trial is called a "Bernoulli" trial, so `bernoulli(theta)` describes a probability model that considers each of the `y` values as being generated by a Bernoulli trial with probability `theta`. It is, of course, the true value of `theta` that we are trying to determine with our data.

### Sampling from the model

Now we sample from the model using our data. (Since there are random processes in play, we'll set the seed to make our work reproducible.)

```{r, cache = TRUE}
set.seed(54321)
fit_bin_unif <- sampling(bin_unif, data = stan_data)
```

There is a lot of output here, showing the progress of running each chain.

### Summarizing the model

Here are some summary statistics for the posterior distribution.

```{r}
fit_bin_unif
```

Ignore the line that starts with `lp__`; we only care about the values of `theta`. With a uniform prior, remember that the posterior is identical to the (scaled) likelihood function. Since 12 out of 18 is $2/3$, the mean of 0.65 makes sense. Of course, there is a range of values for `theta` that is consistent with obtaining 12 successes in 18 trials, and that's represented in the table using the standard deviation `sd` and the percentiles to its right. (Don't worry about `se_mean`, `n_eff`, or `Rhat` for now.)

### Visualizing the model

We can also make a plot of the posterior distribution.

```{r}
plot(fit_bin_unif, plotfun = "dens")
```

Although it's a little rough in shape due to the fact that the posterior is simulated, you can see that it's close to the theoretically correct posterior shown in the "Continuous Bayes" notes. It will be easier to see if we put it on the same x-axis scale as it was there:

```{r}
plot(fit_bin_unif, plotfun = "dens") +
    xlim(0,1)
```

Let's try some other plotting options.

The default option for `plot` gives you 80% and 95% credible intervals for our parameters. We would likely need a much higher "effective sample size" to get good estimates of these, especially at the 95% level, but at least we can see the code we need.

```{r}
plot(fit_bin_unif)
```

The following is a "traceplot" showing the chains. You use this to diagnose chain mixing.

```{r}
plot(fit_bin_unif, plotfun = "trace")
```

This is a histogram of the sampled values of theta:

```{r}
plot(fit_bin_unif, plotfun = "hist")
```

These are diagnostic plots for the MCMC sampling. They are somewhat technical; see the help file for the `stan_diag` function to get more information.

```{r}
plot(fit_bin_unif, plotfun = "diag")
```

Here's a similar series of plots, but for one parameter at a time. We specify the desired parameter using the `par` argument. (The same help page for `stan_diag` also explains the `stan_par` function.)

```{r}
plot(fit_bin_unif, plotfun = "stan_par", par = "theta")
```

This shows the values of $\hat{R}$ for each parameter sampled. There are two bars here because technically the sampler produced `theta` and `lp__`. This plot is not very informative.

```{r}
plot(fit_bin_unif, plotfun = "rhat")
```

Same as the above, but for "ESS", the "Effective Sample Size" (as a proportion of the total number of samples).

```{r}
plot(fit_bin_unif, plotfun = "ess")
```

Same as above, but for the "MCSE", or the "Monte Carlo Standard Error" (as a proportion of the standard deviation in the posterior distribution).

```{r}
plot(fit_bin_unif, plotfun = "mcse")
```

The following graph is slightly more useful. It shows the autocorrelation of the sequence of sampled values. The sequence of values is compared to a "shifted" version of itself. For example, a lag of 1 means that the sequence is compared to a copy of itself shifted over one value. Since one sampled value affects the location of the next sampled value, we would expect there to be some correlation from one value to the next. A lag of 2 compares the sequence to itself shifted by two values. We would expect the correlation to decrease as we move further away from any given sampled value.

We have to pass a parameter to the `pars` argument to tell the `plot` function which parameter we wish to plot.

```{r}
plot(fit_bin_unif, plotfun = "ac", pars = "theta")
```


## Examining the prior

By simply commenting out the likelihood function, we can sample only from the prior.

```{stan, output.var = "bin_unif_prior", cache = TRUE}
data {
    int<lower = 0> N;
    int<lower = 0, upper = 1> y[N];
}
parameters {
    real<lower = 0, upper = 1> theta;
}
model {
    theta ~ uniform(0, 1);  // prior
//    y ~ bernoulli(theta);   // likelihood
}
```

For convenience, we'll also tell the `sampling` function not to print out all the information about processing the chains by using the argument `refresh = 0`.

```{r, cache = TRUE}
set.seed(54321)
fit_bin_unif_prior <- sampling(bin_unif_prior,
                               data = stan_data,
                               refresh = 0)
```

```{r}
fit_bin_unif_prior
```

```{r}
plot(fit_bin_unif_prior, plotfun = "hist")
```

Yep, that looks like a uniform distribution.

Note that the same thing could be done a different way, by simply leaving out the data block. The following is perfectly valid Stan code:

```
parameters {
    real<lower = 0, upper = 1> theta;
}
model {
    theta ~ uniform(0, 1);
}
```

By sampling from that model (leaving out the `data` argument to the `sampling` function), you would also get a uniform distribution. The reason for using the previous method is that in a typical application you do have data, and you do have a model that includes a likelihood function, but you might want to temporarily check that your prior is sensible.


## Normal prior (far from data)

The next example in "Continuous Bayes" is about selecting the normal prior

$$\theta \sim N(0.3, 0.1).$$

Here is the Stan code used to define this model. The only change is the line
```
theta ~ normal(0.3, 0.1);  // prior
```
in the `model` block.

```{stan, output.var = "bin_norm1", cache = TRUE}
data {
    int<lower = 0> N;
    int<lower = 0, upper = 1> y[N];
}
parameters {
    real<lower = 0, upper = 1> theta;
}
model {
    theta ~ normal(0.3, 0.1);   // prior
    y ~ bernoulli(theta);       // likelihood
}
```

Once again, we sample from the model using our data. We'll also tell the `sampling` function not to print out all the information about processing the chains by using the argument `refresh = 0`.

```{r, cache = TRUE}
set.seed(54321)
fit_bin_norm1 <- sampling(bin_norm1,
                          data = stan_data,
                          refresh = 0)
```

```{r}
fit_bin_norm1
```

```{r}
plot(fit_bin_norm1, plotfun = "dens") +
    xlim(0,1)
```

Again, compare this to the theoretical posterior in the `Bayes.Rmd` notes: the mode is a little to the left of 0.5 and most of the distribution is concentrated between about 0.25 to 0.7 or so.


## Normal prior (close to data)

Suppose the prior is

$$\theta \sim N(0.7, 0.1).$$

In the code chunk below, we make the necessary change.

```{stan, output.var = "bin_norm2", cache = TRUE}
data {
    int<lower = 0> N;
    int<lower = 0, upper = 1> y[N];
}
parameters {
    real<lower = 0, upper = 1> theta;
}
model {
    theta ~ normal(0.7, 0.1);   // prior
    y ~ bernoulli(theta);       // likelihood
}
```

```{r, cache = TRUE}
set.seed(54321)
fit_bin_norm2 <- sampling(bin_norm2,
                          data = stan_data,
                          refresh = 0)
```

```{r}
fit_bin_norm2
```

```{r}
plot(fit_bin_norm2, plotfun = "dens") +
    xlim(0,1)
```


## Triangular prior

Stan does not have a built-in expression for a triangular distribution, so we'll leave that example out. (There is a hacky way to make it work, but it's not really worth it. You don't really want to use a triangular distribution for real-world problems anyway.)


## Change the data

The "Continuous Bayes" notes also show the effect of the prior in situations of sparse data. What if we have only 2 successes in 3 trials?

```{r}
N2 <- 3  # Define the sample size
y2 <- c(1, 1, 0)  # 2 successes and 1 failure
stan_data_small <- list(N = N2, y = y2)
```

Let's apply the three models already developed to this new data. Note that we do not need to run any more Stan code. This is just sampling from existing models using new data.

```{r, cache = TRUE}
set.seed(54321)
fit_bin_unif_small <- sampling(bin_unif,
                               data = stan_data_small,
                               refresh = 0)
fit_bin_norm1_small <- sampling(bin_norm1,
                                data = stan_data_small,
                                refresh = 0)
fit_bin_norm2_small <- sampling(bin_norm2,
                                data = stan_data_small,
                                refresh = 0)
```

Summaries and plots:

```{r}
fit_bin_unif_small
```

```{r}
plot(fit_bin_unif_small, plotfun = "dens") +
    xlim(0,1)
```

```{r}
fit_bin_norm1_small
```

```{r}
plot(fit_bin_norm1_small, plotfun = "dens") +
    xlim(0,1)
```

```{r}
fit_bin_norm2_small
```

```{r}
plot(fit_bin_norm2_small, plotfun = "dens") +
    xlim(0,1)
```


## ShinyStan

Shiny is a package that makes interactive web apps and dashboards for R. The Stan developers have created a beautiful dashboard that can be used to diagnose model fit and explore/visualize various properties of the posterior distribution.

Unfortunately, the server configuration does not allow us to open an external tool in a new window, so this only works if you are using Stan installed on your own device. If that is the case, you can type the following:

```
library(shinystan)
launch_shinystan(fit_bin_norm1)
```

There is too much information there to talk about here, and much of it is highly technical. Nevertheless, you can click around and see what's available. Also, in the "More" menu, there is a glossary that defines terms used throughout the dashboard.

