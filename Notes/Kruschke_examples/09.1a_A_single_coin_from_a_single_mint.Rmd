---
title: "9.1(a): A single coin from a single mint"
output: html_notebook
---


## Introduction

This is the first of two models in Section 9.1 of Kruschke. It has a lot of uncertainly about $\omega$, but a high degree of dependence of $\theta$ on $\omega$.


## Preliminaries

Load necessary packages:

```{r, message = FALSE}
library(rstan)
library(shinystan)
library(bayesplot)
```

Set Stan to save compiled code.

```{r}
rstan_options(auto_write = TRUE)
```

Set Stan to use parallel processing where possible.

```{r}
options(mc.cores = parallel::detectCores())
```


## Data

```{r}
N <- 12
y <- c(rep(1, 9), rep(0, 3)) # 9 heads, 3 tails
stan_data <- list(N = N, y = y)
```


## Stan code

We use the `transformed data` block to define constants in our model: $A_{\omega}$ and $B_{\omega}$, the parameters for our beta hyperprior, and $K$, the *concentration* that reflects how tightly $\theta$ should stay to the mode $\omega$.

We use the `transformed parameters` block to define the parameters $a$ and $b$ of the beta prior for $\theta$. This is not strictly necessary, but it makes the `model` block much easier to read.

The `generated quantities` block uses a function that generates a Bernoulli distribution (either 1 or 0 for success or failure) given a probability of success $\theta$. In Stan, this block is run once every time the MCMC process accepts a target; for the value of $\theta$ that happens to be sampled in that round, the `for` loop generates $N$ "coin flips" given that value of $\theta$. The idea is that this becomes "fake data" generated from the posterior distrubution. It's used in a posterior predictive check to make sure that the fake data generated from the posterior is consistent with the actual data we have. (Keep in mind, though, that it won't be a perfect match; after all, the posterior is a compromise between the prior and the likelihood.)

```{stan, output.var = "scsma", cache = TRUE}
data {
    int<lower = 0> N;
    int<lower = 0, upper = 1> y[N];
}
transformed data {
    real<lower = 0> A_omega;
    real<lower = 0> B_omega;
    real<lower = 0> K;

    A_omega = 2;
    B_omega = 2;
    K = 100;
}
parameters {
    real<lower = 0, upper = 1> omega;
    real<lower = 0, upper = 1> theta;
}
transformed parameters {
    real<lower = 0> a;
    real<lower = 0> b;
    
    a = omega * (K - 2) + 1;
    b = (1 - omega) * (K - 2) + 1;
}
model {
    omega ~ beta(A_omega, B_omega);
    theta ~ beta(a, b);
    y ~ bernoulli(theta);
}
generated quantities {
    int<lower = 0, upper = 1> y_rep[N];
    
    for (n in 1:N) {
        y_rep[n] = bernoulli_rng(theta);
    }
}
```


## Sampling from the model

```{r}
set.seed(11111)
fit_scsma <- sampling(scsma, data = stan_data, refresh = 0)
```


## Diagnosing the model

```{r}
plot(fit_scsma, plotfun = "ac", pars = c("omega", "theta"))
```

```{r}
plot(fit_scsma, plotfun = "trace",
     pars = c("omega", "theta"))
```


## Summarizing the model

```{r}
fit_scsma
```


## Visualizing the model

```{r}
pairs(fit_scsma, pars = c("omega", "theta"))
```

```{r}
plot(fit_scsma, pars = c("omega", "theta"))
```


## Examining the prior

Everything is the same here except the likelihood is commented out. (Also the `generated quantities` block is removed. In theory, that block could have been kept, and the fake data it would have generated is often called the "prior predictive distibution".)

```{stan, output.var = "scsma_prior", cache = TRUE}
data {
    int<lower = 0> N;
    int<lower = 0, upper = 1> y[N];
}
transformed data {
    real<lower = 0> A_omega;
    real<lower = 0> B_omega;
    real<lower = 0> K;

    A_omega = 2;
    B_omega = 2;
    K = 100;
}
parameters {
    real<lower = 0, upper = 1> omega;
    real<lower = 0, upper = 1> theta;
}
transformed parameters {
    real<lower = 0> a;
    real<lower = 0> b;
    
    a = omega * (K - 2) + 1;
    b = (1 - omega) * (K - 2) + 1;
}
model {
    omega ~ beta(A_omega, B_omega);
    theta ~ beta(a, b);
//    y ~ bernoulli(theta);
}
```

```{r}
set.seed(11111)
fit_scsma_prior <- sampling(scsma_prior, data = stan_data, refresh = 0)
```

```{r}
fit_scsma_prior
```

```{r}
pairs(fit_scsma_prior, pars = c("omega", "theta"))
```

```{r}
plot(fit_scsma_prior, pars = c("omega", "theta"))
```

All of the above shows that the value of $\theta$ is stongly dependent on the value of $\omega$, the prior mode.


## Posterior predictive check

Extract predicted values:

```{r}
samples_scsma <- extract(fit_scsma)
y_rep <- samples_scsma$y_rep
```

Graph values of $y$ against summaries of $y_{rep}$:

```{r}
ppc_bars(y, y_rep)
```

The bars represent the actual data (9 heads, 3 tails) whereas the dots with error bars represent the range of values in the simulated data from the posterior predictive distribution. Notice the "shrinkage": the posterior predictions are pulled closer to 50% since that was the mode of the prior.


## ShinyStan

Run the following code from the Console:

```
launch_shinystan(fit_scsma)
```